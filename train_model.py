import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB4, ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import os
from tensorflow.keras.callbacks import ReduceLROnPlateau
import numpy as np
from PIL import Image

# ðŸ”¹ RÃ©duction des options CPU pour Ã©viter l'OOM
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"

# ðŸ”¹ DÃ©finition des chemins
DATASET_PATH = "C:/plateforme-agricole-complete-v2/plant_disease_dataset"
MODEL_PATH = "C:/plateforme-agricole-complete-v2/model/efficientnet_resnet.h5"

# ðŸ” VÃ©rification et crÃ©ation du dossier modÃ¨le
os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)

# âœ… **CrÃ©ation du modÃ¨le EfficientNetB4 + ResNet50**
def create_model():
    input_layer = Input(shape=(224, 224, 3), name="input_layer")

    # ðŸ”¹ Ajout de la normalisation
    x = tf.keras.layers.Rescaling(1./255)(input_layer)

    # ðŸ”¹ Bases prÃ©-entraÃ®nÃ©es EfficientNetB4 et ResNet50
    base_model_efficientnet = EfficientNetB4(weights="imagenet", include_top=False, input_tensor=x)
    base_model_resnet = ResNet50(weights="imagenet", include_top=False, input_tensor=x)

    # ðŸ”¹ Fusion des deux modÃ¨les
    x1 = GlobalAveragePooling2D()(base_model_efficientnet.output)
    x2 = GlobalAveragePooling2D()(base_model_resnet.output)
    merged = Concatenate()([x1, x2])

    # ðŸ”¹ Ajout de couches fully connected
    x = Dense(256, activation="relu")(merged)
    x = Dense(128, activation="relu")(x)
    output = Dense(45, activation="softmax", name="output_layer")(x)  # 45 classes

    model = Model(inputs=input_layer, outputs=output)

    return model

# ðŸš€ CrÃ©ation et compilation du modÃ¨le
model = create_model()
model.compile(optimizer=Adam(learning_rate=0.0001), loss="categorical_crossentropy", metrics=["accuracy"])

# ðŸ“Œ **PrÃ©traitement des images avec gestion de transparence**
def preprocess_image(img):
    if isinstance(img, np.ndarray):  # VÃ©rifie si img est un tableau NumPy
        if img.dtype != np.uint8:
            img = (img * 255).astype(np.uint8)  # Convertit les valeurs en uint8
        return img  # âœ… Retourne directement l'image sous format NumPy

    img = np.array(img)  # âœ… Conversion explicite PIL -> NumPy
    img = Image.fromarray(img)  # Reconversion en PIL aprÃ¨s correction
    img = img.convert("RGBA").convert("RGB")  # Supprime la transparence
    return np.array(img)  # âœ… Convertit l'image corrigÃ©e en NumPy avant retour
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_image,
    rescale=1./255,
    rotation_range=20,
    zoom_range=0.15,
    horizontal_flip=True,
    validation_split=0.2
)

train_generator = train_datagen.flow_from_directory(
    os.path.join(DATASET_PATH, "train"),
    target_size=(224, 224),
    batch_size=16,
    class_mode="categorical"
)

val_generator = train_datagen.flow_from_directory(
    os.path.join(DATASET_PATH, "val"),
    target_size=(224, 224),
    batch_size=16,
    class_mode="categorical"
)

# ðŸ”¹ Ajout d'un callback pour ajuster le taux dâ€™apprentissage
lr_callback = ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=3, verbose=1)

# ðŸš€ **EntraÃ®nement du modÃ¨le**
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=25,  # Augmentation des epochs pour une meilleure convergence
    batch_size=16,
    callbacks=[lr_callback]
)

# ðŸ’¾ **Sauvegarde du modÃ¨le avec gestion d'erreur**
try:
    model.save(MODEL_PATH)
    print(f"âœ… ModÃ¨le entraÃ®nÃ© et enregistrÃ© sous {MODEL_PATH}")
except Exception as e:
    print(f"ðŸš¨ Erreur de sauvegarde : {e}")
