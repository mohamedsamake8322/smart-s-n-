import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB4, ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import os
from tensorflow.keras.callbacks import ReduceLROnPlateau
import numpy as np
from PIL import Image

# ğŸ”¹ RÃ©duction des options CPU pour Ã©viter l'OOM
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"

# ğŸ”¹ DÃ©finition des chemins
DATASET_PATH = "C:/plateforme-agricole-complete-v2/plant_disease_dataset"
MODEL_PATH = "C:/plateforme-agricole-complete-v2/model/efficientnet_resnet.h5"

# ğŸ” VÃ©rification et crÃ©ation du dossier modÃ¨le
os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)

# âœ… **CrÃ©ation du modÃ¨le EfficientNetB4 + ResNet50**
def create_model():
    input_layer = Input(shape=(224, 224, 3), name="input_layer")

    # ğŸ”¹ Ajout explicite de la normalisation sur input_layer
    x = tf.keras.layers.Rescaling(1./255)(input_layer)

    # ğŸ”¹ Connexion de EfficientNetB4 et ResNet50 Ã  input_layer
    base_model_efficientnet = EfficientNetB4(weights="imagenet", include_top=False)
    base_model_resnet = ResNet50(weights="imagenet", include_top=False)

    x1 = base_model_efficientnet(x)  # Utilisation de x comme entrÃ©e
    x2 = base_model_resnet(x)  # Connexion Ã  x Ã©galement

    # ğŸ”¹ Fusion des deux modÃ¨les
    x1 = GlobalAveragePooling2D()(x1)
    x2 = GlobalAveragePooling2D()(x2)
    merged = Concatenate()([x1, x2])

    # ğŸ”¹ Ajout de couches fully connected
    x = Dense(256, activation="relu")(merged)
    x = Dense(128, activation="relu")(x)
    output = Dense(45, activation="softmax", name="output_layer")(x)  # 45 classes

    model = Model(inputs=input_layer, outputs=output)

    return model

# ğŸš€ CrÃ©ation et compilation du modÃ¨le
model = create_model()
model.compile(optimizer=Adam(learning_rate=0.0001), loss="categorical_crossentropy", metrics=["accuracy"])

def preprocess_image(img):
    if isinstance(img, np.ndarray):  # VÃ©rifier si img est un tableau NumPy
        if img.dtype != np.uint8:
            img = (img * 255).astype(np.uint8)  # Convertit les valeurs en uint8
        img = Image.fromarray(img)  # âœ… Conversion correcte en image PIL

    img = img.convert("RGBA").convert("RGB")  # Supprimer la transparence
    return np.array(img)  # âœ… Retour sous forme NumPy aprÃ¨s correction


train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_image,
    rotation_range=20,
    zoom_range=0.15,
    horizontal_flip=True,
    validation_split=0.2
)

train_generator = train_datagen.flow_from_directory(
    os.path.join(DATASET_PATH, "train"),
    target_size=(224, 224),
    batch_size=16,
    class_mode="categorical"
)

val_generator = train_datagen.flow_from_directory(
    os.path.join(DATASET_PATH, "val"),
    target_size=(224, 224),
    batch_size=16,
    class_mode="categorical"
)

# ğŸ”¹ Ajout d'un callback pour ajuster le taux dâ€™apprentissage
lr_callback = ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=3, verbose=1)

# ğŸš€ **EntraÃ®nement du modÃ¨le**
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=25,  # Augmentation des epochs pour une meilleure convergence
    batch_size=16,
    callbacks=[lr_callback]
)

# ğŸ’¾ **Sauvegarde du modÃ¨le avec gestion d'erreur**
try:
    model.save(MODEL_PATH)
    print(f"âœ… ModÃ¨le entraÃ®nÃ© et enregistrÃ© sous {MODEL_PATH}")
except Exception as e:
    print(f"ğŸš¨ Erreur de sauvegarde : {e}")
