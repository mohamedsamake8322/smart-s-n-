import dask.dataframe as dd
import pandas as pd
import os
import time


# ğŸ“ Dossier des fichiers
data_dir = r"C:\plateforme-agricole-complete-v2\SmartSÃ¨nÃ¨"

# ğŸ“¦ Liste des fichiers Ã  charger
files = {
    "chirps": "CHIRPS_DAILY_PENTAD.csv",
    "nutrient_balance": "Cropland Nutrient BalanceFAOSTAT_data_en_8-8-2025.csv",
    "trade_matrix": "Detailed trade matrix (fertilizers)FAOSTAT_data_en_8-8-2025.csv",
    "fert_nutrient": "FertilizersbyNutrientFAOSTAT_data_en_8-8-2025.csv",
    "fert_product": "FertilizersbyProductFAOSTAT_data_en_7-22-2025.csv",
    "gedi": "GEDI_Mangrove_CSV.csv",
    "land_cover": "Land CoverFAOSTAT_data_en_8-8-2025.csv",
    "land_use": "Land UseFAOSTAT_data_en_8-8-2025.csv",
    "smap": "SMAP_SoilMoisture.csv",
    "production": "ProductionIndicesFAOSTAT_data_en_7-22-2025.csv",
    "manure": "Livestock ManureFAOSTAT_data_en_8-8-2025.csv",
    "resources": "X_land_water_cleanedRessources en terres et en eau.csv"
}
ignored_files = []
# ğŸŒ Mapping pays
country_mapping = {
    "AlgÃ©rie": "Algeria", "Angola": "Angola", "BÃ©nin": "Benin", "Botswana": "Botswana",
    "Burkina Faso": "Burkina Faso", "Burundi": "Burundi", "Cabo Verde": "Cape Verde",
    "Cameroun": "Cameroon", "RÃ©publique centrafricaine": "CAR", "Tchad": "Chad",
    "Comores": "Comoros", "RÃ©publique du Congo": "Congo", "RÃ©publique dÃ©mocratique du Congo": "DR Congo",
    "CÃ´te d'Ivoire": "Ivory Coast", "Djibouti": "Djibouti", "Ã‰gypte": "Egypt",
    "GuinÃ©e Ã©quatoriale": "Equatorial Guinea", "Ã‰rythrÃ©e": "Eritrea", "Eswatini": "Swaziland",
    "Ã‰thiopie": "Ethiopia", "Gabon": "Gabon", "Gambie": "The Gambia", "Ghana": "Ghana",
    "GuinÃ©e": "Guinea", "GuinÃ©e-Bissau": "Guinea Bissau", "Kenya": "Kenya", "Lesotho": "Lesotho",
    "LibÃ©ria": "Liberia", "Libye": "Libya", "Madagascar": "Madagascar", "Malawi": "Malawi",
    "Mali": "Mali", "Mauritanie": "Mauritania", "Maurice": "Mauritius", "Maroc": "Morocco",
    "Mozambique": "Mozambique", "Namibie": "Namibia", "Niger": "Niger", "NigÃ©ria": "Nigeria",
    "Rwanda": "Rwanda", "Sao TomÃ©-et-Principe": "Sao Tome and Principe", "SÃ©nÃ©gal": "Senegal",
    "Seychelles": "Seychelles", "Sierra Leone": "Sierra Leone", "Somalie": "Somalia",
    "Afrique du Sud": "South Africa", "Soudan du Sud": "South Sudan", "Soudan": "Sudan",
    "Tanzanie": "Tanzania", "Togo": "Togo", "Tunisie": "Tunisia", "Ouganda": "Uganda",
    "Zambie": "Zambia", "Zimbabwe": "Zimbabwe",
}
# ğŸ§¼ Nettoyage personnalisÃ©
def clean_custom_df(df, name):
    df = df.loc[:, ~df.columns.duplicated()]
    df.columns = df.columns.str.strip().str.replace(r'\s+', '_', regex=True)


    # ğŸ¯ Renommage spÃ©cifique
    rename_map = {
        "chirps": {"EXP1_YEAR": "Year"},
        "smap": {"EXP1_YEAR": "Year"},
        "trade_matrix": {"Reporter_Countries": "ADM0_NAME"},
        "production": {"Area": "ADM0_NAME"},
        "manure": {"Area": "ADM0_NAME"},
        "land_use": {"Area": "ADM0_NAME"},
        "land_cover": {"Area": "ADM0_NAME"},
        "fert_nutrient": {"Area": "ADM0_NAME"},
        "fert_product": {"Area": "ADM0_NAME"},
        "nutrient_balance": {"Area": "ADM0_NAME"}
    }
    if name in rename_map:
        df = df.rename(columns=rename_map[name])
    elif name == "resources":
        print(f"âš ï¸ {name} nâ€™a ni ADM0_NAME ni Year â€” fusion latÃ©rale uniquement")
    elif name == "gedi":
        print(f"âš ï¸ {name} nâ€™a pas de colonne Year â€” fusion latÃ©rale uniquement")

    print(f"ğŸ“Š Types dans {name} : {df.dtypes.to_dict()}")

    # ğŸŒ Harmonisation des pays
    if "ADM0_NAME" in df.columns:
        df["ADM0_NAME"] = df["ADM0_NAME"].map(country_mapping, meta=('ADM0_NAME', 'object'))


    # ğŸ“… Conversion de lâ€™annÃ©e
    if "Year" in df.columns:
        try:
            df["Year"] = dd.to_numeric(df["Year"], errors="coerce")
        except AttributeError:
            df["Year"] = df["Year"].astype(float)

    # ğŸ“‹ Log des colonnes
    print(f"ğŸ“‹ Colonnes dans {name} : {list(df.columns)}")

    # ğŸ“› VÃ©rification des clÃ©s
    if "ADM0_NAME" not in df.columns or "Year" not in df.columns:
        ignored_files.append(name)
        print(f"âš ï¸ {name} ignorÃ© pour fusion thÃ©matique")

    return df

# ğŸ“Š Chargement des fichiers
dataframes = {}
for key, filename in files.items():
    path = os.path.join(data_dir, filename)
    try:
        forced_dtypes = {
            "Item_Code": "object",
            "Item_Code_(CPC)": "object",
            "Item Code (CPC)": "object",
            "Area_Code_(M49)": "object",
            "Reporter_Country_Code_(M49)": "object",
            "Partner_Country_Code_(M49)": "object"
        }

        df = dd.read_csv(path, assume_missing=True, dtype=forced_dtypes)
        df_clean = clean_custom_df(df, key)
        dataframes[key] = df_clean

        n_rows = df_clean.shape[0]
        n_rows = n_rows.compute() if hasattr(n_rows, "compute") else n_rows
        print(f"âœ… {key} chargÃ© avec {n_rows:,} lignes")

    except Exception as e:
        print(f"âŒ Erreur chargement {key} : {e}")

# ğŸ“„ Rapport des colonnes
def generate_column_report(dataframes, output_path="rapport_colonnes.csv"):
    rows = []
    for name, df in dataframes.items():
        try:
            cols = df.columns
            types = df.dtypes
            fusionnable = "âœ…" if {"ADM0_NAME", "Year"}.issubset(cols) else "âŒ"
            for col in cols:
                rows.append({
                    "Fichier": name,
                    "Colonne": col,
                    "Type": str(types[col]),
                    "Fusionnable": fusionnable
                })
        except Exception as e:
            rows.append({
                "Fichier": name,
                "Colonne": "âŒ Erreur",
                "Type": str(e),
                "Fusionnable": "âŒ"
            })

    df_report = pd.DataFrame(rows)
    df_report.to_csv(os.path.join(data_dir, output_path), index=False)
    print(f"\nğŸ“„ Rapport colonnes sauvegardÃ© : {output_path}")
generate_column_report(dataframes)

# ğŸ“ RÃ©pertoire de sortie
data_dir = "outputs"
os.makedirs(data_dir, exist_ok=True)

def fusion_progressive(dfs, name, verbose=True):
    print(f"\nğŸ”— Fusion progressive du bloc {name}...")
    required_cols = {"ADM0_NAME", "Year"}
    dfs_valid = [df for df in dfs if required_cols.issubset(df.columns)]

    if not dfs_valid:
        print(f"âš ï¸ Aucun fichier valide pour le bloc {name}")
        return None

    fused = dfs_valid[0]
    total = len(dfs_valid)

    for i, df in enumerate(dfs_valid[1:], start=2):
        source_name = df.attrs.get("source_name", f"{name}_{i}")
        fused = fused.merge(df, how="outer", on=["ADM0_NAME", "Year"], suffixes=("", f"_{source_name}"))
        if verbose:
            print(f"ğŸ”„ Progression fusion {name} : {int((i / total) * 100)}%")
            time.sleep(0.2)

    return fused

# ğŸ§© Fusion par blocs
for k in ['chirps', 'smap', 'land_cover', 'land_use']:
    if k in dataframes:
        dataframes[k].attrs['source_name'] = k
df_climate = fusion_progressive([dataframes[k] for k in ['chirps', 'smap', 'land_cover', 'land_use'] if k in dataframes], "climat")

for k in ['production', 'manure', 'fert_nutrient', 'fert_product', 'nutrient_balance']:
    if k in dataframes:
        dataframes[k].attrs['source_name'] = k
df_production = fusion_progressive([dataframes[k] for k in ['production', 'manure', 'fert_nutrient', 'fert_product', 'nutrient_balance'] if k in dataframes], "production")

# ğŸ§¬ Fusion finale
df_final = None

if df_climate is not None and df_production is not None:
    df_final = df_climate.merge(df_production, on=["ADM0_NAME", "Year"], how="left")
    print("ğŸ”— Fusion thÃ©matique climat + production rÃ©ussie")

    # ğŸ”— Fusion latÃ©rale avec GEDI
    if 'gedi' in dataframes:
        gedi = dataframes['gedi']
        overlap = set(gedi.columns) - {"ADM0_NAME"} & set(df_final.columns)
        if overlap:
            print(f"âš ï¸ Colonnes GEDI dÃ©jÃ  prÃ©sentes : {overlap}")
        df_final = df_final.merge(gedi, on="ADM0_NAME", how="left")
        print("ğŸ”— Fusion latÃ©rale avec GEDI par ADM0_NAME")

    # ğŸ”— Fusion spatiale ou broadcast avec resources
    if 'resources' in dataframes:
        df_resources = dataframes['resources']
        if {'lat', 'lon'}.issubset(df_final.columns):
            df_final = df_final.merge(df_resources, on=["lat", "lon"], how="left")
            print("ğŸ”— Fusion spatiale avec resources par lat/lon")
        else:
            df_resources_broadcast = df_resources.compute()
            for col in df_resources_broadcast.columns:
                df_final[col] = df_resources_broadcast[col].iloc[0]
            print("ğŸ”— Broadcast des variables resources sur tout le dataset")

    # ğŸ§® Conversion en pandas pour entraÃ®nement
    print("\nğŸ§® Conversion en pandas pour entraÃ®nement...")
    try:
        df_final_pd = df_final.persist().compute()
    except Exception as e:
        print(f"âŒ Erreur lors de la conversion en pandas : {type(e).__name__} - {e}")
        df_final_pd = None
else:
    print("âŒ Fusion finale impossible : blocs climat ou production manquants")

def audit_final(df: pd.DataFrame, output_path: str = "dataset_rendement_prepared.csv.gz", verbose: bool = True, drop_constants: bool = False):
    if df is None:
        print("âŒ Aucun DataFrame Ã  auditer.")
        return

    # âœ… Dimensions
    n_rows, n_cols = df.shape
    if verbose:
        print(f"\nâœ… Fusion finale rÃ©ussie : {n_rows:,} lignes, {n_cols} colonnes")
        print(f"ğŸ“‹ Colonnes fusionnÃ©es (extrait) : {df.columns.tolist()[:15]} ...")

    # ğŸ“‰ Valeurs manquantes
    missing = df.isna().sum().sort_values(ascending=False)
    missing_nonzero = missing[missing > 0]
    if not missing_nonzero.empty:
        print("\nğŸ“‰ Valeurs manquantes par colonne :")
        print(missing_nonzero)
        missing_nonzero.to_csv(os.path.join(data_dir, "rapport_missing_values.csv"))
        print("ğŸ“ Rapport des valeurs manquantes sauvegardÃ©.")
    else:
        print("\nâœ… Aucune valeur manquante dÃ©tectÃ©e.")

    # âš ï¸ Colonnes constantes
    constant_cols = [col for col in df.columns if df[col].nunique(dropna=False) <= 1]
    if constant_cols:
        print(f"\nâš ï¸ Colonnes constantes dÃ©tectÃ©es : {constant_cols}")
        pd.Series(constant_cols).to_csv(os.path.join(data_dir, "rapport_colonnes_constantes.csv"), index=False)
        print("ğŸ“ Rapport des colonnes constantes sauvegardÃ©.")
        if drop_constants:
            df = df.drop(columns=constant_cols)
            print("ğŸ§¹ Colonnes constantes supprimÃ©es avant sauvegarde.")
    else:
        print("\nâœ… Aucune colonne constante dÃ©tectÃ©e.")

    # ğŸ’¾ Sauvegarde du dataset
    full_path = os.path.join(data_dir, output_path)
    df.to_csv(full_path, index=False, compression="gzip")
    print(f"\nâœ… Fichier sauvegardÃ© : {full_path}")

# ğŸ“‹ Audit final
audit_final(df_final_pd, drop_constants=True)
