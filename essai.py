from transformers import Blip2Processor, Blip2ForConditionalGeneration
from PIL import Image
import torch

# ğŸ“ Chemin vers une image de ton dataset
img_path = "C:/plateforme-agricole-complete-v2/plantdataset/train/Thrips/img_001.jpg"

# ğŸ§  Charger le modÃ¨le BLIP2-OPT
processor = Blip2Processor.from_pretrained("Salesforce/blip2-opt-2.7b")
model = Blip2ForConditionalGeneration.from_pretrained("Salesforce/blip2-opt-2.7b", device_map="auto", torch_dtype=torch.float16)

# ğŸ–¼ï¸ Charger l'image
image = Image.open(img_path).convert("RGB")

# ğŸ—£ï¸ Prompt de test
prompt = "Describe the symptoms of the plant disease in this image."

# ğŸ” PrÃ©paration
inputs = processor(images=image, text=prompt, return_tensors="pt").to("cuda", torch.float16)

# ğŸš€ GÃ©nÃ©ration
generated_ids = model.generate(**inputs, max_new_tokens=50)
caption = processor.tokenizer.decode(generated_ids[0], skip_special_tokens=True)

print(f"ğŸ§  Caption gÃ©nÃ©rÃ©e : {caption}")
